{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/thucth/thucth/project/insightface/recognition/arcface_torch\n"
     ]
    }
   ],
   "source": [
    "%cd /home/thucth/thucth/project/insightface/recognition/arcface_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Arcface into AdaFace heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embs.shape:  torch.Size([2, 512])\n",
      "norm.shape:  torch.Size([2, 1])\n",
      "labels.shape:  torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Dummy input/labels\n",
    "embs = torch.randn(2,512)\n",
    "norm = torch.norm(embs,2,dim=-1,keepdim=True)\n",
    "embs = torch.div(embs, norm)\n",
    "labels = torch.tensor([6,9])\n",
    "print(\"embs.shape: \",embs.shape) \n",
    "print(\"norm.shape: \",norm.shape) \n",
    "print(\"labels.shape: \",labels.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "\n",
    "def l2_norm(input,axis=-1):\n",
    "    norm = torch.norm(input,2,axis,True)\n",
    "    output = torch.div(input, norm)\n",
    "    return output\n",
    "class AdaFaceWAct(torch.nn.Module):\n",
    "    ''' \n",
    "    1. Multiply embeddings with W (W phase)\n",
    "    2. Compute Adaface Activate (like normalized softmax) (Act phase)\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 embedding_size=512,\n",
    "                 classnum=70722,\n",
    "                 m=0.4,\n",
    "                 h=0.333,\n",
    "                 s=64.,\n",
    "                 t_alpha=1.0,\n",
    "                 ):\n",
    "        super(AdaFaceWAct, self).__init__()\n",
    "        self.classnum = classnum\n",
    "        self.kernel = torch.nn.Parameter(torch.Tensor(embedding_size,classnum))\n",
    "        # # initial kernel\n",
    "        self.kernel.data.uniform_(-1, 1).renorm_(2,1,1e-5).mul_(1e5)\n",
    "        # self.kernel = torch.nn.Parameter(torch.ones(embedding_size,classnum)) for debug without randomness\n",
    "\n",
    "        self.m = m \n",
    "        self.eps = 1e-3\n",
    "        self.h = h\n",
    "        self.s = s\n",
    "\n",
    "        # ema prep\n",
    "        self.t_alpha = t_alpha\n",
    "        self.register_buffer('t', torch.zeros(1))\n",
    "        self.register_buffer('batch_mean', torch.ones(1)*(20))\n",
    "        self.register_buffer('batch_std', torch.ones(1)*100)\n",
    "\n",
    "        print('\\n\\AdaFaceWAct with the following property')\n",
    "        print('self.m', self.m)\n",
    "        print('self.h', self.h)\n",
    "        print('self.s', self.s)\n",
    "        print('self.t_alpha', self.t_alpha)\n",
    "\n",
    "    def forward(self, embbedings, norms, label):\n",
    "        kernel_norm = l2_norm(self.kernel,axis=0)\n",
    "        print(kernel_norm)\n",
    "        cosine = torch.mm(embbedings,kernel_norm)\n",
    "        cosine = cosine.clamp(-1+self.eps, 1-self.eps) # for stability\n",
    "        \n",
    "        print(cosine)\n",
    "        \n",
    "        safe_norms = torch.clip(norms, min=0.001, max=100) # for stability\n",
    "        safe_norms = safe_norms.clone().detach()\n",
    "\n",
    "        # update batchmean batchstd\n",
    "        with torch.no_grad():\n",
    "            mean = safe_norms.mean().detach()\n",
    "            std = safe_norms.std().detach()\n",
    "            self.batch_mean = mean * self.t_alpha + (1 - self.t_alpha) * self.batch_mean\n",
    "            self.batch_std =  std * self.t_alpha + (1 - self.t_alpha) * self.batch_std\n",
    "\n",
    "        margin_scaler = (safe_norms - self.batch_mean) / (self.batch_std+self.eps) # 66% between -1, 1\n",
    "        margin_scaler = margin_scaler * self.h # 68% between -0.333 ,0.333 when h:0.333\n",
    "        margin_scaler = torch.clip(margin_scaler, -1, 1)\n",
    "        # ex: m=0.5, h:0.333\n",
    "        # range\n",
    "        #       (66% range)\n",
    "        #   -1 -0.333  0.333   1  (margin_scaler)\n",
    "        # -0.5 -0.166  0.166 0.5  (m * margin_scaler)\n",
    "\n",
    "        # g_angular\n",
    "        m_arc = torch.zeros(label.size()[0], cosine.size()[1], device=cosine.device)\n",
    "        m_arc.scatter_(1, label.reshape(-1, 1), 1.0)\n",
    "        g_angular = self.m * margin_scaler * -1\n",
    "        m_arc = m_arc * g_angular\n",
    "        theta = cosine.acos()\n",
    "        theta_m = torch.clip(theta + m_arc, min=self.eps, max=math.pi-self.eps)\n",
    "        cosine = theta_m.cos()\n",
    "\n",
    "        # g_additive\n",
    "        m_cos = torch.zeros(label.size()[0], cosine.size()[1], device=cosine.device)\n",
    "        m_cos.scatter_(1, label.reshape(-1, 1), 1.0)\n",
    "        g_add = self.m + (self.m * margin_scaler)\n",
    "        m_cos = m_cos * g_add\n",
    "        cosine = cosine - m_cos\n",
    "        # scale\n",
    "        scaled_cosine_m = cosine * self.s\n",
    "        return scaled_cosine_m\n",
    "\n",
    "cross_entropy_loss = CrossEntropyLoss()\n",
    "\n",
    "adaface_w_act = AdaFaceWAct(embedding_size=512,\n",
    "                 classnum=10,\n",
    "                 m=0.4,\n",
    "                 h=0.333,\n",
    "                 s=64.,\n",
    "                 t_alpha=1.0)\n",
    "\n",
    "logits = adaface_w_act(embs,norm,labels)\n",
    "\n",
    "loss_train = cross_entropy_loss(logits, labels)\n",
    "print(loss_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperate W and Act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def l2_norm(input,axis=-1):\n",
    "    norm = torch.norm(input,2,axis,True)\n",
    "    output = torch.div(input, norm)\n",
    "    return output\n",
    "    \n",
    "class AdaFC(torch.nn.Module):\n",
    "    ''' \n",
    "    1. Multiply embeddings with W (FC phase)\n",
    "    2. Compute Adaface Activate (like normalized softmax) (Act phase)\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 margin_loss: Callable,\n",
    "                 embedding_size=512,\n",
    "                 classnum=70722,\n",
    "                 ):\n",
    "        super(AdaFC, self).__init__()\n",
    "        self.classnum = classnum\n",
    "        self.kernel = torch.nn.Parameter(torch.Tensor(embedding_size,classnum))\n",
    "        self.kernel.data.uniform_(-1, 1).renorm_(2,1,1e-5).mul_(1e5)\n",
    "        # self.kernel = torch.nn.Parameter(torch.ones(embedding_size,classnum)) for debug without randomness\n",
    "\n",
    "        self.dist_cross_entropy = CrossEntropyLoss()\n",
    "\n",
    "        # margin_loss\n",
    "        if isinstance(margin_loss, Callable):\n",
    "            self.margin_softmax = margin_loss\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "        # initial kernel\n",
    "        self.eps = 1e-3\n",
    "\n",
    "    def forward(self, embbedings, norms, labels):\n",
    "        kernel_norm = l2_norm(self.kernel,axis=0)\n",
    "        print(kernel_norm)\n",
    "        logits = torch.mm(embbedings,kernel_norm)\n",
    "        logits = logits.clamp(-1+self.eps, 1-self.eps) # for stability\n",
    "        print(logits)\n",
    "        logits = self.margin_softmax(logits,norms, labels)\n",
    "        loss = self.dist_cross_entropy(logits, labels)\n",
    "        return loss\n",
    "\n",
    "class AdaAct(torch.nn.Module):\n",
    "    ''' \n",
    "    This version is modified as ArcFace method\n",
    "    1. Multiply embeddings with W (FC phase)\n",
    "    2. Compute Adaface Activate (like normalized softmax) (Act phase)\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 m=0.4,\n",
    "                 h=0.333,\n",
    "                 s=64.,\n",
    "                 t_alpha=1.0,\n",
    "                 ):\n",
    "        super(AdaAct, self).__init__()\n",
    "        self.m = m \n",
    "        self.eps = 1e-3\n",
    "        self.h = h\n",
    "        self.s = s\n",
    "        \n",
    "        # ema prep\n",
    "        self.t_alpha = t_alpha\n",
    "        self.register_buffer('batch_mean_z', torch.ones(1)*(20))\n",
    "        self.register_buffer('batch_std_z', torch.ones(1)*100)\n",
    "\n",
    "        print('\\n\\AdaFaceWAct with the following property')\n",
    "        print('self.m', self.m)\n",
    "        print('self.h', self.h)\n",
    "        print('self.s', self.s)\n",
    "        print('self.t_alpha', self.t_alpha)\n",
    "\n",
    "    def forward(self, logits:torch.Tensor, norms:torch.Tensor, labels:torch.Tensor):\n",
    "\n",
    "        logits = logits.clamp(-1+self.eps, 1-self.eps) # for stability\n",
    "        \n",
    "        safe_norms = torch.clip(norms, min=0.001, max=100) # for stability\n",
    "        safe_norms = safe_norms.clone().detach()\n",
    "\n",
    "        # update batchmean batchstd\n",
    "        with torch.no_grad():\n",
    "            mean_z = safe_norms.mean().detach()\n",
    "            std_z = safe_norms.std().detach()\n",
    "            self.batch_mean_z = mean_z * self.t_alpha + (1 - self.t_alpha) * self.batch_mean_z\n",
    "            self.batch_std_z =  std_z * self.t_alpha + (1 - self.t_alpha) * self.batch_std_z\n",
    "\n",
    "\n",
    "        z = (safe_norms - self.batch_mean_z) / (self.batch_std_z+self.eps)\n",
    "        z = z * self.h \n",
    "        z = torch.clip(z, -1, 1)\n",
    "\n",
    "        # g_angular shape(2,1)\n",
    "        g_angular = - self.m * z \n",
    "        g_angular = g_angular.reshape(-1)\n",
    "        \n",
    "        index = torch.where(labels != -1)[0]\n",
    "        target_logits = logits[index, labels[index].view(-1)]\n",
    "        print(target_logits)\n",
    "        theta = target_logits.acos()\n",
    "        theta_m = torch.clip(theta + g_angular, min=self.eps, max=math.pi-self.eps)######\n",
    "        target_logits_angular = theta_m.cos()\n",
    "\n",
    "        # g_additive sahpe(2,1)\n",
    "        g_add = self.m + (self.m * z)\n",
    "        g_add = g_add.reshape(-1)\n",
    "        target_logits_add = target_logits_angular - g_add\n",
    "        # this is not easy_marin in arcface\n",
    "        gap_ = 1 - self.m*z - self.m - (self.m*z).cos()\n",
    "        gap_ = gap_.reshape(-1)\n",
    "\n",
    "        final_target_logits = torch.where(theta + g_angular > 0, target_logits_add, target_logits+gap_)\n",
    "\n",
    "        logits[index, labels[index].view(-1)] = final_target_logits\n",
    "        logits = logits * self.s\n",
    "        return logits\n",
    "\n",
    "class AdaActOrigin(torch.nn.Module):\n",
    "    ''' \n",
    "    This version is modified as Ogirinal ArcFace \n",
    "    1. Multiply embeddings with W (FC phase)\n",
    "    2. Compute Adaface Activate (like normalized softmax) (Act phase)\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 m=0.4,\n",
    "                 h=0.333,\n",
    "                 s=64.,\n",
    "                 t_alpha=1.0,\n",
    "                 ):\n",
    "        super(AdaActOrigin, self).__init__()\n",
    "        self.m = m \n",
    "        self.eps = 1e-3\n",
    "        self.h = h\n",
    "        self.s = s\n",
    "        \n",
    "        # ema prep\n",
    "        self.t_alpha = t_alpha\n",
    "        self.register_buffer('batch_mean_z', torch.ones(1)*(20))\n",
    "        self.register_buffer('batch_std_z', torch.ones(1)*100)\n",
    "\n",
    "        print('\\n\\AdaFaceWAct with the following property')\n",
    "        print('self.m', self.m)\n",
    "        print('self.h', self.h)\n",
    "        print('self.s', self.s)\n",
    "        print('self.t_alpha', self.t_alpha)\n",
    "\n",
    "    def forward(self, logits:torch.Tensor, norms:torch.Tensor, labels:torch.Tensor):\n",
    "        logits = logits.clamp(-1+self.eps, 1-self.eps) # for stability\n",
    "        \n",
    "        safe_norms = torch.clip(norms, min=0.001, max=100) # for stability\n",
    "        safe_norms = safe_norms.clone().detach()\n",
    "\n",
    "        # update batchmean batchstd\n",
    "        with torch.no_grad():\n",
    "            mean_z = safe_norms.mean().detach()\n",
    "            std_z = safe_norms.std().detach()\n",
    "            self.batch_mean_z = mean_z * self.t_alpha + (1 - self.t_alpha) * self.batch_mean_z\n",
    "            self.batch_std_z =  std_z * self.t_alpha + (1 - self.t_alpha) * self.batch_std_z\n",
    "\n",
    "\n",
    "        margin_scaler = (safe_norms - self.batch_mean_z) / (self.batch_std_z+self.eps) # 66% between -1, 1\n",
    "        margin_scaler = margin_scaler * self.h # 68% between -0.333 ,0.333 when h:0.333\n",
    "        margin_scaler = torch.clip(margin_scaler, -1, 1)\n",
    "        # ex: m=0.5, h:0.333\n",
    "        # range\n",
    "        #       (66% range)\n",
    "        #   -1 -0.333  0.333   1  (margin_scaler)\n",
    "        # -0.5 -0.166  0.166 0.5  (m * margin_scaler)\n",
    "\n",
    "        # g_angular\n",
    "        m_arc = torch.zeros(labels.size()[0], logits.size()[1], device=logits.device)\n",
    "        m_arc.scatter_(1, labels.reshape(-1, 1), 1.0)\n",
    "        g_angular = self.m * margin_scaler * -1\n",
    "        m_arc = m_arc * g_angular\n",
    "        theta = logits.acos()\n",
    "        theta_m = torch.clip(theta + m_arc, min=self.eps, max=math.pi-self.eps)\n",
    "        logits = theta_m.cos()\n",
    "\n",
    "        # g_additive\n",
    "        m_cos = torch.zeros(labels.size()[0], logits.size()[1], device=logits.device)\n",
    "        m_cos.scatter_(1, labels.reshape(-1, 1), 1.0)\n",
    "        g_add = self.m + (self.m * margin_scaler)\n",
    "        m_cos = m_cos * g_add\n",
    "        logits = logits - m_cos\n",
    "\n",
    "        # scale\n",
    "        scaled_logits_m = logits * self.s\n",
    "        return scaled_logits_m\n",
    "\n",
    "\n",
    "ada_act = AdaAct(m=0.4, h=0.333, s=64., t_alpha=1.0)\n",
    "# ada_act = AdaActOrigin(m=0.4, h=0.333, s=64., t_alpha=1.0)\n",
    "ada_fc = AdaFC(margin_loss=ada_act, embedding_size=512, classnum=10)\n",
    "\n",
    "loss = ada_fc(embs, norm, labels)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial Ada FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "    rank = int(os.environ[\"RANK\"])\n",
    "    distributed.init_process_group(\"nccl\")\n",
    "except KeyError:\n",
    "    world_size = 1\n",
    "    rank = 0\n",
    "    distributed.init_process_group(\n",
    "        backend=\"nccl\",\n",
    "        init_method=\"tcp://127.0.0.1:12584\",\n",
    "        rank=rank,\n",
    "        world_size=world_size,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from typing import Callable\n",
    "\n",
    "import torch\n",
    "from torch import distributed\n",
    "from torch.nn.functional import linear, normalize\n",
    "\n",
    "class AllGatherFunc(torch.autograd.Function):\n",
    "    \"\"\"AllGather op with gradient backward\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, tensor, *gather_list):\n",
    "        gather_list = list(gather_list)\n",
    "        distributed.all_gather(gather_list, tensor)\n",
    "        return tuple(gather_list)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, *grads):\n",
    "        grad_list = list(grads)\n",
    "        rank = distributed.get_rank()\n",
    "        grad_out = grad_list[rank]\n",
    "\n",
    "        dist_ops = [\n",
    "            distributed.reduce(grad_out, rank, distributed.ReduceOp.SUM, async_op=True)\n",
    "            if i == rank\n",
    "            else distributed.reduce(\n",
    "                grad_list[i], i, distributed.ReduceOp.SUM, async_op=True\n",
    "            )\n",
    "            for i in range(distributed.get_world_size())\n",
    "        ]\n",
    "        for _op in dist_ops:\n",
    "            _op.wait()\n",
    "\n",
    "        grad_out *= len(grad_list)  # cooperate with distributed loss function\n",
    "        return (grad_out, *[None for _ in range(len(grad_list))])\n",
    "\n",
    "AllGather = AllGatherFunc.apply\n",
    "\n",
    "class DistCrossEntropyFunc(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    CrossEntropy loss is calculated in parallel, allreduce denominator into single gpu and calculate softmax.\n",
    "    Implemented of ArcFace (https://arxiv.org/pdf/1801.07698v1.pdf):\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, logits: torch.Tensor, label: torch.Tensor):\n",
    "        \"\"\" \"\"\"\n",
    "        batch_size = logits.size(0)\n",
    "        # for numerical stability\n",
    "        max_logits, _ = torch.max(logits, dim=1, keepdim=True)\n",
    "        # local to global\n",
    "        distributed.all_reduce(max_logits, distributed.ReduceOp.MAX)\n",
    "        logits.sub_(max_logits)\n",
    "        logits.exp_()\n",
    "        sum_logits_exp = torch.sum(logits, dim=1, keepdim=True)\n",
    "        # local to global\n",
    "        distributed.all_reduce(sum_logits_exp, distributed.ReduceOp.SUM)\n",
    "        logits.div_(sum_logits_exp)\n",
    "        index = torch.where(label != -1)[0]\n",
    "        # loss\n",
    "        loss = torch.zeros(batch_size, 1, device=logits.device)\n",
    "        loss[index] = logits[index].gather(1, label[index])\n",
    "        distributed.all_reduce(loss, distributed.ReduceOp.SUM)\n",
    "        ctx.save_for_backward(index, logits, label)\n",
    "        return loss.clamp_min_(1e-30).log_().mean() * (-1)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, loss_gradient):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            loss_grad (torch.Tensor): gradient backward by last layer\n",
    "        Returns:\n",
    "            gradients for each input in forward function\n",
    "            `None` gradients for one-hot label\n",
    "        \"\"\"\n",
    "        (\n",
    "            index,\n",
    "            logits,\n",
    "            label,\n",
    "        ) = ctx.saved_tensors\n",
    "        batch_size = logits.size(0)\n",
    "        one_hot = torch.zeros(\n",
    "            size=[index.size(0), logits.size(1)], device=logits.device\n",
    "        )\n",
    "        one_hot.scatter_(1, label[index], 1)\n",
    "        logits[index] -= one_hot\n",
    "        logits.div_(batch_size)\n",
    "        return logits * loss_gradient.item(), None\n",
    "\n",
    "class DistCrossEntropy(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistCrossEntropy, self).__init__()\n",
    "\n",
    "    def forward(self, logit_part, label_part):\n",
    "        return DistCrossEntropyFunc.apply(logit_part, label_part)\n",
    "\n",
    "class AdaPartialFC(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    https://arxiv.org/abs/2203.15565\n",
    "    A distributed sparsely updating variant of the FC layer, named Partial FC (PFC).\n",
    "\n",
    "    When sample rate less than 1, in each iteration, positive class centers and a random subset of\n",
    "    negative class centers are selected to compute the margin-based softmax loss, all class\n",
    "    centers are still maintained throughout the whole training process, but only a subset is\n",
    "    selected and updated in each iteration.\n",
    "\n",
    "    .. note::\n",
    "        When sample rate equal to 1, Partial FC is equal to model parallelism(default sample rate is 1).\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    >>> module_pfc = AdaPartialFC(embedding_size=512, num_classes=8000000, sample_rate=0.2)\n",
    "    >>> for img, labels in data_loader:\n",
    "    >>>     embeddings = net(img)\n",
    "    >>>     loss = module_pfc(embeddings, labels, optimizer)\n",
    "    >>>     loss.backward()\n",
    "    >>>     optimizer.step()\n",
    "    \"\"\"\n",
    "    _version = 1 \n",
    "    def __init__(\n",
    "        self,\n",
    "        margin_loss: Callable,\n",
    "        embedding_size: int,\n",
    "        num_classes: int,\n",
    "        sample_rate: float = 1.0,\n",
    "        fp16: bool = False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Paramenters:\n",
    "        -----------\n",
    "        embedding_size: int\n",
    "            The dimension of embedding, required\n",
    "        num_classes: int\n",
    "            Total number of classes, required\n",
    "        sample_rate: float\n",
    "            The rate of negative centers participating in the calculation, default is 1.0.\n",
    "        \"\"\"\n",
    "        super(AdaPartialFC, self).__init__()\n",
    "        assert (\n",
    "            distributed.is_initialized()\n",
    "        ), \"must initialize distributed before create this\"\n",
    "        self.rank = distributed.get_rank()\n",
    "        self.world_size = distributed.get_world_size()\n",
    "\n",
    "        self.dist_cross_entropy = DistCrossEntropy()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.sample_rate: float = sample_rate\n",
    "        self.fp16 = fp16\n",
    "        self.num_local: int = num_classes // self.world_size + int(\n",
    "            self.rank < num_classes % self.world_size\n",
    "        )\n",
    "        self.class_start: int = num_classes // self.world_size * self.rank + min(\n",
    "            self.rank, num_classes % self.world_size\n",
    "        )\n",
    "        self.num_sample: int = int(self.sample_rate * self.num_local)\n",
    "        self.last_batch_size: int = 0\n",
    "        self.weight: torch.Tensor\n",
    "        self.weight_mom: torch.Tensor\n",
    "        self.weight_activated: torch.nn.Parameter\n",
    "        self.weight_activated_mom: torch.Tensor\n",
    "        self.is_updated: bool = True\n",
    "        self.init_weight_update: bool = True\n",
    "\n",
    "        self.weight_activated = torch.nn.Parameter(torch.normal(0, 0.01, (self.num_local, embedding_size)))\n",
    "\n",
    "        # margin_loss\n",
    "        if isinstance(margin_loss, Callable):\n",
    "            self.margin_softmax = margin_loss\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update(self):\n",
    "        \"\"\" partial weight to global\n",
    "        \"\"\"\n",
    "        if self.init_weight_update:\n",
    "            self.init_weight_update = False\n",
    "            return\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        local_embeddings: torch.Tensor,\n",
    "        norms:torch.Tensor,\n",
    "        local_labels: torch.Tensor\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        ----------\n",
    "        local_embeddings: torch.Tensor\n",
    "            feature embeddings on each GPU(Rank).\n",
    "        local_labels: torch.Tensor\n",
    "            labels on each GPU(Rank).\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        loss: torch.Tensor\n",
    "            pass\n",
    "        \"\"\"\n",
    "\n",
    "        local_labels.squeeze_()\n",
    "        local_labels = local_labels.long()\n",
    "        self.update()\n",
    "\n",
    "        batch_size = local_embeddings.size(0)\n",
    "        if self.last_batch_size == 0:\n",
    "            self.last_batch_size = batch_size\n",
    "        assert self.last_batch_size == batch_size, (\n",
    "            \"last batch size do not equal current batch size: {} vs {}\".format(\n",
    "            self.last_batch_size, batch_size))\n",
    "\n",
    "        _gather_embeddings = [\n",
    "            torch.zeros((batch_size, self.embedding_size)).cuda()\n",
    "            for _ in range(self.world_size)\n",
    "        ]\n",
    "        _gather_labels = [\n",
    "            torch.zeros(batch_size).long().cuda() for _ in range(self.world_size)\n",
    "        ]\n",
    "        _list_embeddings = AllGather(local_embeddings, *_gather_embeddings)\n",
    "        distributed.all_gather(_gather_labels, local_labels)\n",
    "\n",
    "        embeddings = torch.cat(_list_embeddings)\n",
    "        labels = torch.cat(_gather_labels)\n",
    "\n",
    "        labels = labels.view(-1, 1)\n",
    "        index_positive = (self.class_start <= labels) & (\n",
    "            labels < self.class_start + self.num_local\n",
    "        )\n",
    "        labels[~index_positive] = -1\n",
    "        labels[index_positive] -= self.class_start\n",
    "        with torch.cuda.amp.autocast(self.fp16):\n",
    "            norm_embeddings = normalize(embeddings)\n",
    "            norm_weight_activated = normalize(self.weight_activated)\n",
    "            logits = linear(norm_embeddings, norm_weight_activated)\n",
    "        if self.fp16:\n",
    "            logits = logits.float()\n",
    "        logits = logits.clamp(-1, 1)\n",
    "        logits = self.margin_softmax(logits, norms, labels)\n",
    "        loss = self.dist_cross_entropy(logits, labels)\n",
    "        return loss\n",
    "\n",
    "    def state_dict(self, destination=None, prefix=\"\", keep_vars=False):\n",
    "        if destination is None: \n",
    "            destination = collections.OrderedDict()\n",
    "            destination._metadata = collections.OrderedDict()\n",
    "\n",
    "        for name, module in self._modules.items():\n",
    "            if module is not None:\n",
    "                module.state_dict(destination, prefix + name + \".\", keep_vars=keep_vars)\n",
    "        if self.sample_rate < 1:\n",
    "            destination[\"weight\"] = self.weight.detach()\n",
    "        else:\n",
    "            destination[\"weight\"] = self.weight_activated.data.detach()\n",
    "        return destination\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\AdaFaceWAct with the following property\n",
      "self.m 0.4\n",
      "self.h 0.333\n",
      "self.s 64.0\n",
      "self.t_alpha 1.0\n",
      "> \u001b[0;32m/tmp/ipykernel_75059/2401976465.py\u001b[0m(238)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    236 \u001b[0;31m        \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    237 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 238 \u001b[0;31m        \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmargin_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    239 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    240 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "tensor([ 0.0052, -0.0297], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor(31.1257, device='cuda:0', grad_fn=<DistCrossEntropyFuncBackward>)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ada_act = AdaAct(m=0.4, h=0.333, s=64., t_alpha=1.0)\n",
    "# ada_act = AdaActOrigin(m=0.4, h=0.333, s=64., t_alpha=1.0)\n",
    "ada_fc = AdaPartialFC(margin_loss=ada_act, embedding_size=512, num_classes=10)\n",
    "ada_fc.cuda()\n",
    "loss = ada_fc(embs.cuda(), norm.cuda(), labels.cuda())\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MxFaceDataset to remove failed samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thucth/.conda/envs/torch19/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# from dataset import MXFaceDataset\n",
    "import mxnet as mx\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = \"/mnt/data/WebFace42M_shufrec\"\n",
    "root_dir = \"/mnt/data/MS1MV2\"\n",
    "\n",
    "path_imgrec = os.path.join(root_dir, 'train.rec')\n",
    "path_imgidx = os.path.join(root_dir, 'train.idx')\n",
    "imgrec = mx.recordio.MXIndexedRecordIO(path_imgidx, path_imgrec, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x08\\x06\\x06\\x07\\x06\\x05\\x08\\x07\\x07\\x07\\t\\t\\x08\\n\\x0c\\x14\\r\\x0c\\x0b\\x0b\\x0c\\x19\\x12\\x13\\x0f\\x14\\x1d\\x1a\\x1f\\x1e\\x1d\\x1a\\x1c\\x1c $.\\' \",#\\x1c\\x1c(7),01444\\x1f\\'9=82<.342\\xff\\xdb\\x00C\\x01\\t\\t\\t\\x0c\\x0b\\x0c\\x18\\r\\r\\x182!\\x1c!22222222222222222222222222222222222222222222222222\\xff\\xc0\\x00\\x11\\x08\\x00p\\x00p\\x03\\x01\"\\x00\\x02\\x11\\x01\\x03\\x11\\x01\\xff\\xc4\\x00\\x1f\\x00\\x00\\x01\\x05\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\t\\n\\x0b\\xff\\xc4\\x00\\xb5\\x10\\x00\\x02\\x01\\x03\\x03\\x02\\x04\\x03\\x05\\x05\\x04\\x04\\x00\\x00\\x01}\\x01\\x02\\x03\\x00\\x04\\x11\\x05\\x12!1A\\x06\\x13Qa\\x07\"q\\x142\\x81\\x91\\xa1\\x08#B\\xb1\\xc1\\x15R\\xd1\\xf0$3br\\x82\\t\\n\\x16\\x17\\x18\\x19\\x1a%&\\'()*456789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\\x83\\x84\\x85\\x86\\x87\\x88\\x89\\x8a\\x92\\x93\\x94\\x95\\x96\\x97\\x98\\x99\\x9a\\xa2\\xa3\\xa4\\xa5\\xa6\\xa7\\xa8\\xa9\\xaa\\xb2\\xb3\\xb4\\xb5\\xb6\\xb7\\xb8\\xb9\\xba\\xc2\\xc3\\xc4\\xc5\\xc6\\xc7\\xc8\\xc9\\xca\\xd2\\xd3\\xd4\\xd5\\xd6\\xd7\\xd8\\xd9\\xda\\xe1\\xe2\\xe3\\xe4\\xe5\\xe6\\xe7\\xe8\\xe9\\xea\\xf1\\xf2\\xf3\\xf4\\xf5\\xf6\\xf7\\xf8\\xf9\\xfa\\xff\\xc4\\x00\\x1f\\x01\\x00\\x03\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\t\\n\\x0b\\xff\\xc4\\x00\\xb5\\x11\\x00\\x02\\x01\\x02\\x04\\x04\\x03\\x04\\x07\\x05\\x04\\x04\\x00\\x01\\x02w\\x00\\x01\\x02\\x03\\x11\\x04\\x05!1\\x06\\x12AQ\\x07aq\\x13\"2\\x81\\x08\\x14B\\x91\\xa1\\xb1\\xc1\\t#3R\\xf0\\x15br\\xd1\\n\\x16$4\\xe1%\\xf1\\x17\\x18\\x19\\x1a&\\'()*56789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\\x82\\x83\\x84\\x85\\x86\\x87\\x88\\x89\\x8a\\x92\\x93\\x94\\x95\\x96\\x97\\x98\\x99\\x9a\\xa2\\xa3\\xa4\\xa5\\xa6\\xa7\\xa8\\xa9\\xaa\\xb2\\xb3\\xb4\\xb5\\xb6\\xb7\\xb8\\xb9\\xba\\xc2\\xc3\\xc4\\xc5\\xc6\\xc7\\xc8\\xc9\\xca\\xd2\\xd3\\xd4\\xd5\\xd6\\xd7\\xd8\\xd9\\xda\\xe2\\xe3\\xe4\\xe5\\xe6\\xe7\\xe8\\xe9\\xea\\xf2\\xf3\\xf4\\xf5\\xf6\\xf7\\xf8\\xf9\\xfa\\xff\\xda\\x00\\x0c\\x03\\x01\\x00\\x02\\x11\\x03\\x11\\x00?\\x00\\xf7\\xea(\\xa6H\\xe24,{\\x0c\\xd2n\\xc0U\\xbe\\xb9\\x16\\xf1\\xe7#q\\xe9\\\\\\xbd\\xdc\\xef\\xe6,\\x11sq?9?\\xc2;\\xb1\\xab\\xb7S\\xb3\\xc8\\xd2>O\\xf7V\\xb2w}\\x9f\\xcc\\x9aF\\x1et\\x9c\\xbb\\x7fuG\\xf0\\xd7\\x1dI\\xf33\\xa2\\x11\\xb0\\xeb\\xab\\xc4\\xd3-\\x85\\xbd\\xa6\\xe6\\x91\\xcf\\xde<\\x965\\x85}t\\xd6\\x89\\xf6m\\xfb\\xae\\x1f\\xe6\\x99\\xfb\\x0e\\xf8\\xfc*\\xdaL\\x03Iz\\xe0\\x9e\\xab\\x10=I\\xeej\\xb5\\x85\\x83]\\xdc\\xb4\\xf2\\x8e\\xbc\\xf3\\xd9}O\\xd7\\xfa\\n\\xca\\xf76J\\xda\\x95,m\\xf6\\xa4\\x97\\x97@\\x8e\\x84\\x03\\xd7\\xff\\x00\\xd7W-l\\xda{\\x83q\\'\\x03\\xa1\\x1f\\xdd\\x1e\\x83\\xdf5m\\xa1k\\xeb\\xb1\\x0ck\\x88#<\\x9fV\\xab\\xd2F\\xb6\\xf1yi\\xf30\\xfet\\xadq\\xdc\\xc3\\xd5ZI\\x9d`\\x89@\\xcf\\x19\\x1d\\xbd\\xff\\x00\\x0f\\xe7Y\\xedj\\x8b*A\\x18\\xcaD79\\xcfS\\xdb\\xf5\\xad\\xf7\\x88 $|\\xd2\\xb8\\xc0\"\\xab\\xfd\\x9b\\xc8\\x19#\\x90r\\xde\\xed\\xd8~\\x15-X\\xb4e_\\x97\\x11\\xa4\\x07\\x9e\\xcd\\xeez\\x9f\\xf0\\xfc+\\x97\\xbe\\xb3x\\xe62\\xc1!\\x88\\x8e\\xdd\\x8dw\\xf6\\xd6\"w\\xf9\\xd7ws\\xf5\\xaa\\xda\\xa6\\x83\\x1b\\xc6v\\x12\\xad\\x8e(I\\xeeRkc\\x89\\x8fY\\xb9\\x8c\\x88.\\x95Y;\\x10r?\\x03\\xda\\xaeC\\xa8\\xb2I\\xba\\tYXv\\xea++S\\xb16\\xac\\xca\\xea1\\xeb\\xe9U-\\xe5hp\\xf9\\xdc\\xa3\\x8c\\xa9\\xce*\\xb9P\\x99\\xf5\\x1dP\\xd4f\\xd9\\x19\\x03\\xbd_\\xae{V\\xbd\\x1ek\"u\\x07\\x15\\xddVVG\\x9d\\x15vg\\xdc\\xcf\\xe5\\x82T|\\xc7\\xbdd2\\x9b\\x86bX\\x88\\x90\\xfc\\xc7\\xfb\\xc7\\xd2\\xad\\xb4\\x9ek\\x90\\x0f\\x03\\xef7\\xa5B\\x90\\x8b\\x80\\x11\\x07\\x97\\x02zw\\xae7\\xa9\\xd4\\xb4 X\\x9aY\\x94\\xec\\xf9q\\x88\\xd3\\xfa\\xfd*\\xcb\\x02\\x91\\x9bH[.\\xfc\\xc8\\xf5\"\\xe3;b\\x00v\\xdd\\xedS\"$*B\\x80[\\xad\\t\\x0e\\xe2\\xc5\\x1cvV\\xfb\\x14\\xe0\\x91\\xc9?\\xe7\\xadB\\xfbW\\xe7n\\x06:w\\xa6J\\xf9q\\x83\\x929\\xa9!\\x80\\x9cK.v\\x8e\\x80\\xf74\\xc6\\x97R\\x15GQ\\xe6\\xb0\\xc4\\x8d\\xc4k\\xe8=i<\\xaf3\\xe5\\x1c\\xe3\\xbf\\xa9\\xeej\\xd9\\x1b\\x9c\\xb1\\xe5\\x8f\\x18\\xf4\\x15f\\xde\\xdf\\x9d\\xcc(P\\xb8\\xee%\\xa5\\xa2\\xc5\\x18\\xe3\\x9a\\x87P\\x83r6+On\\xd1U\\xe7]\\xc0\\xd6\\x8e:\\x12\\xa5vy~\\xbd\\x10/\"\\xb0\\xe7\\xbf\\x1d\\xab\\x8c\\x95~\\xcf#m%A\\xea:\\x8a\\xf4\\x7f\\x14Y0&EM\\xcb\\xfc\\xab\\x81\\xbc\\x8c:\\xfc\\xea\\x0e;\\x91\\xc8\\xac\\x93\\xe8l\\xf6\\xb9\\xf4\\xed\\xdc\\xebol\\xf21\\xc0\\x02\\xb8;\\xab\\xe5i\\xdd\\x8b\\x0c\\x93\\xf9WY\\xaa\\xdeA%\\x9bD\\x08m\\xde\\xf5\\xc4\\\\A\\x0cre~\\xf1\\xe9\\xde\\xaf\\x11+\\xbb#\\x96\\x92\\xd3Rh\\xd9\\xe7l\\xb6R\\x11\\xdb\\xfb\\xd5$\\x97\\x8a\\xd9E\\x00F;/SY\\xf7w\\x82\\xd6\\x10H/\\xce1\\x9cW\\x1b\\xa9x\\xce[K\\x89U\\xe3\\x8e(\\xd4p\\x07,j\"\\x9b\\xd1\\x1a\\xb5\\xdc\\xf4\\x112\\x81\\x88fUc\\xd1\\\\\\xe3\\x152[\\xdc\\xba\\xe3z\\x01\\xdd\\xb7f\\xbc:\\xe7\\xe2\\x14\\x97\\x0eUmT\\xa0\\xfe&<\\xfe\\x1e\\x95\\xd1x/\\xc6F\\xea\\xf4Z\\xc9s&\\x1c\\xfd\\xc9\\x9bv>\\x86\\xb4\\xf6RZ\\x89I7\\xa1\\xeaB\\x14\\x88\\xfc\\xcd\\xbc\\xf6\\x0bR\\x13$\\x9c\\xb1\\x08\\xa3\\xd7\\xb5:\\xdds\\x1e\\xee\\xf5\\xcfx\\x86\\x1b\\xdb\\x86\\x08\\x97&+p9\\x0b\\xf7\\x89\\xa1D\\xab\\x17\\xee|E\\xa6\\xd89\\x8d\\x1d\\xa7\\x9f\\xfb\\xa83N\\xb7\\xd55\\xab\\xf5\\xdfkg\\x14I\\xdb\\xcdj\\xf2\\xfdK]]\\x0eC\\x15\\xb4(\\\\u\\x91\\xcf5F/\\x8a:\\x95\\xbb`\\x05+\\xe8\\rl\\xa0\\xc9r\\x8a\\xd2\\xe7\\xb5\\xae\\xa7\\x7fm\\x81\\x7f`B\\xf7\\x92&\\xdc\\x07\\xe1W\\xe3\\xb9\\x82\\xe57E\"\\xba\\xfb\\x1a\\xf2\\xad#\\xe2\\xb1\\xb9q\\x14\\xea\\x01>\\xb5\\xdbi\\x1a\\xb5\\xae\\xa2\\xfed\\x08\\x15\\x8f\\xde\\xda1\\x9aR\\x8d\\x81+\\xab\\x9a\\x1a\\x95\\xa2\\\\B\\xc0\\x81^K\\xe2Kf\\xb0\\xbb.\\xaa\\n\\x9f\\xbc\\xa6\\xbd\\x91\\xc6\\xe5\\xaf9\\xf1\\xc5\\xb6T\\x91\\xc1\\xacd\\xb5./\\xa1\\xda\\xea\\x86\\xe8Jv\\x03\\x8e\\xdc\\xf5\\xac\\xed\\xcc\\xd1\\xee\\x991\\x83\\x9e\\xb9\\xad\\xab\\xb9VI_\\x9c\\xb68\\x03\\xbdgL#\\xd9\\x820\\xd8\\xe9\\xebX\\xb5\\xa9+c&\\xf4\\x89\\xad$n\\x988\\xc5y\\xa7\\x89t\\xa9o\\xae\\xd2H\\x98\\r\\xc0\\xabd~_\\xd6\\xbd\\x03T.-\\x9e\\x05\\xf9K\\xb6F\\x0fOz\\xc0\\xb3\\x8c_\\xebf!\\xca@\\xbc\\xe7\\xb9\\xcdT[N\\xe8\\xd1E5fd\\xe9k\\xa6Z\\xf8J\\xff\\x00B\\xbe\\x81\\xe0\\xbcrLw\\x02\\x02\\xc1\\xfb\\x8c\\x90+;\\xc3\\xfa\\x05\\xe7\\xf6\\x89\\x9c\\xd9\\xc8\\x06G\\x94\"]\\xaa\\xa7=Ny\\xc5z\\xd5\\xb6\\x99\\x1e\\xc0J\\x8f\\xca\\xb4-\\xec\\xe3\\x12\\xae\\x14WW\\xb4m\\x18\\xfb4\\x99\\xa9e\\x13\\x0be\\xdd\\xd7o5N\\xf6\\xd7\\xcd\\'#\\x8a\\xda\\n\\x12!U\\xdd\\x15\\xaal;\\x9eE\\xfd\\x95ig\\xe2i.\\xf5\\xcd2{\\x98\\x03\\xfe\\xe9T\\x06@=H\\xef\\\\\\xdf\\x8c\\xec,\\xee\\xbcE%\\xde\\x94\\x81\\xa0\\xb89 \\xc2\\xca\\xc80\\x01\\\\\\x1e1\\xc7Q\\xcd{\\x94\\xdabL\\xd9 \\x1a\\x88h\\xd1\\xee\\xe5A\\xfa\\x8a\\xd3\\x9d\\xa4K\\x82n\\xe7\\x8ci~\\x06\\x97R\\xbc\\x8aX\\xa1\\x92\\xce\\xd9T\\x03\\xbc\\xe5\\x98\\x81\\xc9\\xc7j\\xf5\\xdd\\x0bD\\x8bK\\xb7X\\xe3\\x1d:\\x93\\xd4\\xd6\\xc4\\x16\\x11\\xc6>\\xe8\\xa9\\xce\\xc4\\x18\\x15\\r\\xb7\\xb9I%\\xa2\"n\\x05q~3\\xb72\\xda\\xee\\x1d{\\xd7_4\\xe1A\\xae\\x7fS\\xc5\\xe7\\xee\\xb1\\x90k\\x19\\xb3h.\\xe5\\xbb\\x9b\\x86\\x82\\xe8\\\\\\x04\\x0c\\x9b\\xb8\\x1d\\xb9\\xac\\xc9o\\x9e\\xe6\\xe1B\\xbe\\x06r\\xc3\\xda\\xae5\\xc3Of\\x91.\\x08\\x1c\\xf1\\xd6\\xb0n\\xe1\\x96\\x19\\x19\\xa3\\x078\\xce\\x05apQ%\\xb9\\x84\\xde,\\xaa\\x9c0\\x19R+\\x0f\\xc3\\xcf\\xe5\\xf8\\x8aD\\x93\\x89\\x196\\x9f|U\\xcf\\xed\\x05\\x81\\x1d\\xf7\\x91*\\xf2\\x10\\x9e\\xb5\\x96eU\\xbe\\x8a\\xfe3\\x87\\x0c\\x19\\xf1\\xde\\xb4\\x88\\xedc\\xd3\\xe1PPb\\xaeZB\\x1a\\\\\\x9e\\x82\\xb3lf\\x0f\\n\\xb0<\\x10\\x08\\xabmp`\\x1b\\xc1\\xfa\\xd6\\xd1\\xb1\\x9c\\x91\\xb4\\xca\\nrqX\\xb7S4\\x0e\\xce\\x0f\\xca\\x0f5V\\xf6\\xf2\\xf6x\\x80\\xb5\\xfb\\xfd\\xb7t\\xac\\xe8\\xee5\\x19\\xe1kK\\x88?|x.\\xa3\\xe5>\\xf4\\xe6\\xc2\\x10\\xeeuV\\x93,\\xd1\\x06\\x07\\xadL\\xdbG5B\\xca\\x13m\\n)\\xec0jy$\\xf9j\\xaf\\xa1\\x0e:\\xe86k\\x90\\xa2\\xb3\\xe5\\xbc\\'\\xbd%\\xc3\\x13\\x9a\\xa2\\xc0\\xe6\\xb2l\\xda1Aqr\\xcd\\xd0\\xd5h\\xc1/\\x92y\\xa9v\\x129\\xa8~eu\\xc0\\xc9g\\n\\x05f\\xca\\xba(i\\xd7\\xf3Da\\x8aH\\xc9G\\x1cc\\xadZ\\xd4\\'V\\x9c\\xbcCn\\x0f#\\x15\\x89$\\xc5\\x1b\\xcao\\xbaO\\xca}\\x0f\\xb5G\\x1d\\xe3\\xb4\\xe2\\x19>\\xf9\\xe3 \\xf5\\xa8)\\xc7[\\x8b\\xabAgw\\x02\\xb3 \\x8ac\\xfcj2\\rr\\xb3\\xf9\\xf6LH\\x98H\\x99\\xe2\\xba\\xedh\\xa6\\x9f:D\\x84:\\x94\\x04\\x9cw\\xeb\\\\\\xed\\xf5\\xacO6\\x14~\\xeeA\\x9e*\\x916;\\xbf\\x0b]\\x8b\\xbd\"\\x07\\x07\\xa0\\xdaG\\xa6+r\\xe2\\xe2(\\x80\\xdeG=\\x05q^\\t\\x9b\\xec\\xbeu\\x937\\xfbK\\x9f\\xd6\\xb5\\xf5\\x1d>\\xe2\\xee\\xe4\\xb7\\xda\\x9a8\\xd8q\\x81\\xc8\\xada\\xa8\\x92M\\xeak\\x7fiB\\x08\\xf9\\x80\\xc7`9\\xab\\x96\\xd7\\xf6\\xd20_1U\\xfd\\x1a\\xb9[_\\x0f\\\\[\\xc3\\xe5\\x8b\\xd10\\x19\\xf9\\xe5\\x00\\xb7\\xe7N\\x9fB\\xbc\\x9c\\xc6R\\xf5 \\xd9\\xd4F\\xa3\\xe6\\xfa\\xe6\\xb5\\xe5-\\xc2\\'nd\\x07\\xadD\\xed\\x9a\\xe6,\\xac\\xb5xgU\\x17\\xc8\\xf1\\x03\\xceW\\xa8\\xae\\x8d\\t\\xda7u\\xa8fN*$O\\x1ej\\x17\\x88U\\xb6`*\\xbc\\xd2\\xaa\\xa9&\\xa4WeIG8\\xa4\\x80\\x0f\\xb5\\xc7\\x9e\\x8as\\xf8\\xd4&\\xe1K\\x92y\\x15=\\xa2\\xb1p\\xc7\\xbf5\\x9b)\\xad\\x0c\\rCM\\x02V\\x8d\\xb3\\x90k:\\x15\\x8e\\xde\\xf2?\\xb5De\\x887%I\\x0c\\x05w:\\xed\\x96$\\x12*\\xf2=\\xab\\rl\\x96c\\xf7s\\x9a\\xa7\\x1b;\\x15\\x19\\xdd\\x10x\\xad\\xb4\\xeb\\xdd\\x16\\x1b\\xebY\\x17\\x7f\\x9c\\xe9\\x8f\\xe2\\xc0\\xe9\\x91\\xda\\xb8\\x04\\x9d\\xd6\\xe0F\\xc0\\x9c\\xfd\\xda\\xf4\\t\\xb4H\\xc5\\xbb!A\\x8c\\xe7\\xa5b&\\x93\\x1a\\xde*\\x14\\xe4\\x12G\\xbf\\xb5)\\xabj\\x11i+!\\x96\\x07\\xf7\\xd1\\xddC\\xc4\\x88~a\\xea+\\xba\\x85\\x05\\xccj\\xcaxa\\x91Y\\xbaW\\x87.\\x15\\xcco\\x07\\xca\\xd8\\xc1\\xc5uv\\x9a\\x03\\xc7f\\xcb\\x1b|\\xe8r\\xaa\\x7f\\x95*wn\\xc6s\\x9cQ\\x964tnH\\xe4\\xfaT\\x89\\xa4\\xec\\xfb\\xbcU\\xbf\\xb4=\\xb9\\xd94l\\xac?\\xbc)N\\xa2\\x98\\xed]\\x16B\\xe6\\x93\\xd8\\xae\\x96\\xed\\x1d+|\\xbdj9\\xb5$\\xc1\\xe4VM\\xce\\xa4\\xef\\x91\\x18&\\xa1\\x8d&\\xcb\\xd7\\x17k\\x18<\\xd65\\xc5\\xf1\\x91\\xb6\\xadB\\xd1\\\\N~f U\\xbbk\\x15L\\x1cd\\xfa\\x9a\\x86\\xcd\\x14m\\xb8\\x96\\xb0\\xb3\\x9d\\xcc?\\n\\xdc\\xb7\\x8c\\x01U\\xe1\\x84.8\\xab^\\\\\\xd2\\x83\\x1d\\xba\\xee\\x90\\x8e\\x06qP\\x93\\xb8\\xa4\\xf4?\\xff\\xd9'\n"
     ]
    }
   ],
   "source": [
    "s = imgrec.read_idx(2)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header, _ = mx.recordio.unpack(s)\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = imgrec.read_idx(0)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #extract infomation from old rec \n",
    "# s = imgrec.read_idx(0)\n",
    "# header, _ = mx.recordio.unpack(s)\n",
    "# if header.flag > 0:\n",
    "#     header0 = (int(header.label[0]), int(header.label[1]))\n",
    "#     imgidx = np.array(range(1, int(header.label[0])))\n",
    "# else:\n",
    "#     imgidx = np.array(list(imgrec.keys))\n",
    "# print(len(imgidx))\n",
    "# #write header record\n",
    "# imgrec_new.write_idx(0,s)\n",
    "\n",
    "# #write the rest records, if which record is broken, ignore it\n",
    "# idx_new=1\n",
    "# failed_idx=[]\n",
    "# for idx in tqdm(imgidx):\n",
    "#     try:\n",
    "#         s = imgrec.read_idx(idx)\n",
    "#         header, img = mx.recordio.unpack(s)\n",
    "#         label = header.label\n",
    "#         label = torch.tensor(label, dtype=torch.long)\n",
    "#         sample = mx.image.imdecode(img).asnumpy()\n",
    "#         if np.isnan(sample).any():\n",
    "#             failed_idx.append(idx)\n",
    "#             raise(Exception(\"nan\"))\n",
    "#         if sample.shape[0]<=0:\n",
    "#             failed_idx.append(idx)\n",
    "#             raise(Exception(\"nan\"))\n",
    "#         if np.count_nonzero(sample) <= 5:\n",
    "#             failed_idx.append(idx)\n",
    "#             raise(Exception(\"nan\"))\n",
    "#         # imgrec_new.write_idx(idx_new, s)\n",
    "#         idx_new+=1\n",
    "#     except Exception as e:\n",
    "#         failed_idx.append(idx)\n",
    "#         print(idx)\n",
    "#         raise e\n",
    "#         continue\n",
    "\n",
    "# imgrec.close()\n",
    "# imgrec_new.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#extract infomation from old rec \n",
    "s = imgrec.read_idx(0)\n",
    "header, _ = mx.recordio.unpack(s)\n",
    "if header.flag > 0:\n",
    "    header0 = (int(header.label[0]), int(header.label[1]))\n",
    "    imgidx = np.array(range(1, int(header.label[0])))\n",
    "else:\n",
    "    imgidx = np.array(list(imgrec.keys))\n",
    "print(len(imgidx))\n",
    "\n",
    "#write the rest records, if which record is broken, ignore it\n",
    "idx_new=1\n",
    "failed_idx=[]\n",
    "for idx in tqdm(imgidx[:10]):\n",
    "    try:\n",
    "        s = imgrec.read_idx(idx)\n",
    "        header, img = mx.recordio.unpack(s)\n",
    "        label = header.label\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        sample = mx.image.imdecode(img).asnumpy()\n",
    "        plt.imshow(sample)\n",
    "        plt.show()\n",
    "        if np.isnan(sample).any():\n",
    "            failed_idx.append(idx)\n",
    "            raise(Exception(\"nan\"))\n",
    "        if sample.shape[0]<=0:\n",
    "            failed_idx.append(idx)\n",
    "            raise(Exception(\"nan\"))\n",
    "        if np.count_nonzero(sample) <= 5:\n",
    "            failed_idx.append(idx)\n",
    "            raise(Exception(\"nan\"))\n",
    "        # imgrec_new.write_idx(idx_new, s)\n",
    "        idx_new+=1\n",
    "    except Exception as e:\n",
    "        failed_idx.append(idx)\n",
    "        print(idx)\n",
    "        raise e\n",
    "\n",
    "imgrec.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/thucth/thucth/project/insightface/recognition/arcface_torch/experiments.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bws6/home/thucth/thucth/project/insightface/recognition/arcface_torch/experiments.ipynb#ch0000014vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m#extract infomation from old rec \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bws6/home/thucth/thucth/project/insightface/recognition/arcface_torch/experiments.ipynb#ch0000014vscode-remote?line=1'>2</a>\u001b[0m s \u001b[39m=\u001b[39m imgrec\u001b[39m.\u001b[39mread_idx(\u001b[39m100\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bws6/home/thucth/thucth/project/insightface/recognition/arcface_torch/experiments.ipynb#ch0000014vscode-remote?line=2'>3</a>\u001b[0m header, _ \u001b[39m=\u001b[39m mx\u001b[39m.\u001b[39;49mrecordio\u001b[39m.\u001b[39;49munpack(s)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bws6/home/thucth/thucth/project/insightface/recognition/arcface_torch/experiments.ipynb#ch0000014vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(header)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bws6/home/thucth/thucth/project/insightface/recognition/arcface_torch/experiments.ipynb#ch0000014vscode-remote?line=4'>5</a>\u001b[0m imgrec\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.conda/envs/torch19/lib/python3.9/site-packages/mxnet/recordio.py:419\u001b[0m, in \u001b[0;36munpack\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munpack\u001b[39m(s):\n\u001b[1;32m    397\u001b[0m     \u001b[39m\"\"\"Unpack a MXImageRecord to string.\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \n\u001b[1;32m    399\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[39m    HEADER(flag=0, label=14.0, id=20129312, id2=0)\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     header \u001b[39m=\u001b[39m IRHeader(\u001b[39m*\u001b[39mstruct\u001b[39m.\u001b[39munpack(_IR_FORMAT, s[:_IR_SIZE]))\n\u001b[1;32m    420\u001b[0m     s \u001b[39m=\u001b[39m s[_IR_SIZE:]\n\u001b[1;32m    421\u001b[0m     \u001b[39mif\u001b[39;00m header\u001b[39m.\u001b[39mflag \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#extract infomation from old rec \n",
    "s = imgrec.read_idx(100)\n",
    "header, _ = mx.recordio.unpack(s)\n",
    "print(header)\n",
    "imgrec.close()\n",
    "imgrec_new.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mxnet.recordio.MXIndexedRecordIO at 0x7fe10c1c7b80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgrec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('torch19')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00d88ef73131cde97a726bc4328e2378448ded265cd4801d80b7f8b089f25486"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
